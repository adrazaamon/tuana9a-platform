apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-backup
  namespace: coder
spec:
  schedule: "0 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          initContainers:
            - name: set-params
              image: busybox
              command:
                - "sh"
                - "-c"
                - |
                  OBJECT_KEY="$(date +'%Y%m%d%H')-coder-postgres-dump.tar.gz"
                  echo $OBJECT_KEY > /data/object_key.env
                  date +%s > /data/start.time
                  cat /data/start.time
                  ls -la /data/
              volumeMounts:
                - name: workdir
                  mountPath: /data

            - name: dump
              image: postgres:16
              command:
                - "sh"
                - "-c"
                - |
                  export PGPASSWORD=$PG_PASS; pg_dump -v -h $PG_HOST -p ${PG_PORT:-5432} -U $PG_USER -d $PG_DATABASE > /data/dump.sql
                  ls -la /data/
              volumeMounts:
                - name: workdir
                  mountPath: /data
              envFrom:
                - secretRef:
                    name: coder-postgres-backup-env

            - name: zip
              image: busybox:latest
              command:
                - "sh"
                - "-c"
                - |
                  cd /data
                  tar -czvf dump.tar.gz dump.sql
                  ls -la /data/
              volumeMounts:
                - name: workdir
                  mountPath: /data

            - name: upload
              image: amazon/aws-cli:2.18.0
              command:
                - "sh"
                - "-c"
                - |
                  OBJECT_KEY=$(cat /data/object_key.env)
                  aws s3api --endpoint-url ${S3_ENDPOINT} put-object --bucket ${BUCKET_NAME} --key $OBJECT_KEY --body /data/dump.tar.gz
                  echo upload completed
                  date +%s > /data/stop.time
                  cat /data/stop.time
                  ls -la /data/
              envFrom:
                - secretRef:
                    name: coder-postgres-backup-env
              volumeMounts:
                - name: workdir
                  mountPath: /data

            - name: notify
              image: alpine/curl
              command:
                - sh
                - -c
                - |
                  START_TIME=$(cat "/data/start.time")
                  STOP_TIME=$(cat "/data/stop.time")
                  DURATION=$((STOP_TIME - START_TIME))
                  OBJECT_KEY=$(cat /data/object_key.env)
                  # MSG=":white_check_mark: \`backup-postgres\` \`coder\` \`$(($DURATION / 60))m$(($DURATION % 60))s\`"
                  # curl -X POST "${DISCORD_WEBHOOK}" -H "Content-Type: application/json" -d "{\"content\":\"${MSG}\"}"
                  push_gateway_baseurl="http://prometheus-prometheus-pushgateway.prometheus.svc.cluster.local:9091"
                  cat <<EOF | curl --data-binary @- $push_gateway_baseurl/metrics/job/postgres_backup_cronjob
                  # TYPE postgres_backup_duration gauge
                  postgres_backup_duration{namespace="$POD_NAMESPACE"} $DURATION
                  # TYPE postgres_backup_unixtimestamp gauge
                  postgres_backup_unixtimestamp{namespace="$POD_NAMESPACE"} $(date +%s)
                  EOF
              envFrom:
                - secretRef:
                    name: coder-postgres-backup-env
              env:
                - name: POD_NAMESPACE
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.namespace
              volumeMounts:
                - name: workdir
                  mountPath: /data

          containers:
            - name: done
              image: busybox:latest
              command: ["sh", "-c", "echo done"]
          restartPolicy: Never
          volumes:
            - name: workdir
              emptyDir: {}
